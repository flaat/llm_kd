"""
LLM Experiment Runner

This script provides a command-line interface for running various language model experiments,
including testing models and generating counterfactual explanations. It provides options to:

1. Select worker and refiner model names and sizes
2. Configure generation parameters (temperature, top-p, etc.)
3. Choose the dataset for experiments
4. Run with plain or fine-tuned models (separately for worker and refiner)

The script serves as the main entry point for the LLM experimentation framework.
"""
import argparse
from typing import Dict, Any
from src.pipeline import test_llm


def parse_arguments() -> argparse.Namespace:
    """
    Parse command-line arguments for the experiment runner.
    
    Returns:
        Namespace containing all parsed arguments
    """
    parser = argparse.ArgumentParser(
        description="Run language model experiments with configurable parameters."
    )

    # Model configuration parameters
    parser.add_argument(
        '--worker_model_name',
        type=str,
        default='phi_4B',
        help='Worker model name to use for experiments (default: phi_4B)'
    )

    parser.add_argument(
        '--refiner_model_name',
        type=str,
        default='phi_4B',
        help='Refiner model name to use for experiments (default: phi_4B)'
    )

    parser.add_argument(
        '--max_model_len',
        type=int,
        default=8192,
        help='Maximum context length for the model (default: 8192)'
    )
    
    parser.add_argument(
        '--worker_fine_tuned',
        action='store_true',
        help='Use fine-tuned version of the WORKER model instead of the base model'
    )

    parser.add_argument(
        '--refiner_fine_tuned',
        action='store_true',
        help='Use fine-tuned version of the REFINER model instead of the base model'
    )

    parser.add_argument(
        '--refiner',
        action='store_true',
        help='Use refiner model for generating explanations'
    )

    # Generation parameters
    parser.add_argument(
        '--temperature',
        type=float,
        default=0.6,
        help='Temperature for text generation - higher values increase randomness (default: 0.6)'
    )
    
    parser.add_argument(
        '--top_p',
        type=float,
        default=0.8,
        help='Top-p (nucleus) sampling parameter - lower values increase determinism (default: 0.8)'
    )
    
    parser.add_argument(
        '--max_tokens',
        type=int,
        default=4096,
        help='Maximum number of tokens to generate (default: 4096)'
    )
    
    parser.add_argument(
        '--repetition_penalty',
        type=float,
        default=1.05,
        help='Penalty applied to repeating tokens - higher values discourage repetition (default: 1.05)'
    )

    parser.add_argument(
        '--num_narratives',
        type=int,
        default=3,
        help='Number of draft explanations generated by the worker and passed to the refiner (default: 3)'
    )

    # Data and experiment type parameters
    parser.add_argument(
        '--dataset',
        type=str,
        default='adult',
        choices=['adult', 'california', 'titanic', 'diabetes'],
        help='Dataset to use for experiments (default: adult)'
    )
    

    parser.add_argument(
        '--analyze_feasibility',
        action='store_true',
        help='Analyze the feasibility of the LLM for the given task'
    )

    return parser.parse_args()


def display_config(args: argparse.Namespace) -> None:
    """
    Display the experiment configuration parameters.
    
    Args:
        args: Parsed command-line arguments
    """
    print("\n========== EXPERIMENT CONFIGURATION ==========")
    print(f"Worker model name:   {args.worker_model_name}")
    print(f"Refiner model name:  {args.refiner_model_name}")
    print(f"Model context length: {args.max_model_len}")
    print(f"Worker fine-tuned:   {'Yes' if args.worker_fine_tuned else 'No'}")
    print(f"Refiner fine-tuned:  {'Yes' if args.refiner_fine_tuned else 'No'}")
    print(f"Using refiner:       {'Yes' if args.refiner else 'No'}")
    print(f"Analyzing feasibility: {'Yes' if args.analyze_feasibility else 'No'}")
    print("\n----- Generation Parameters -----")
    print(f"Temperature:         {args.temperature}")
    print(f"Top-p:               {args.top_p}")
    print(f"Max tokens:          {args.max_tokens}")
    print(f"Repetition penalty:  {args.repetition_penalty}")
    print(f"Num narratives (worker -> refiner): {args.num_narratives}")
    print("\n----- Experiment Settings -----")
    print(f"Dataset:             {args.dataset}")
    print(f"Testing LLM:         {'Yes' if args.test_llm else 'No'}")
    print("=============================================\n")


def main() -> None:
    """
    Main entry point for the LLM experimentation framework.
    
    Parses command-line arguments, displays configuration, and runs
    the requested experiment pipeline based on argument values.
    """
    # Parse command-line arguments
    args = parse_arguments()
    
    # Display configuration for user verification
    display_config(args)
    
    # Run the selected experiment pipeline
    test_llm(
        worker_model_name=args.worker_model_name,
        refiner_model_name=args.refiner_model_name if args.refiner else None,
        dataset=args.dataset,
        temperature=args.temperature,
        top_p=args.top_p,
        max_tokens=args.max_tokens,
        repetition_penalty=args.repetition_penalty,
        max_model_len=args.max_model_len,
        refiner=args.refiner,
        worker_fine_tuned=args.worker_fine_tuned,
        refiner_fine_tuned=args.refiner_fine_tuned,
        analyze_feasibility=args.analyze_feasibility,
        num_narratives=args.num_narratives,
    )


if __name__ == "__main__":
    main()
